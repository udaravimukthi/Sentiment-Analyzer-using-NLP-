{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from collections import defaultdict\n",
    "from nltk import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init bigram model for positive & negative comments\n",
    "# init with 0 counts\n",
    "# dictionaries to hold the bigram frequencies\n",
    "model_p = defaultdict(lambda:defaultdict(lambda: 0))\n",
    "model_n = defaultdict(lambda:defaultdict(lambda: 0))\n",
    "\n",
    "# dictionaries to hold the probabilities for each bigram\n",
    "prob_model_p = defaultdict(lambda:defaultdict(lambda: 0.))\n",
    "prob_model_n = defaultdict(lambda:defaultdict(lambda: 0.))\n",
    "\n",
    "# tokenizer to tokenize the comments & remove stop words\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "# utility functions\n",
    "\n",
    "# Returns the list of sample lines from csv\n",
    "def get_dataset(path):\n",
    "    lines = []\n",
    "    with open(path) as file:\n",
    "        lines = file.read().splitlines()\n",
    "    return lines\n",
    "\n",
    "# Creates bigrams using the text provided\n",
    "def make_bigrams(comment):\n",
    "    tokens = tokenizer.tokenize(comment.lower()) # convert to all lowercase\n",
    "    return [(tokens[x], tokens[x+1]) for x in range(len(tokens) - 1)]\n",
    "\n",
    "# utility functions end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core functions\n",
    "\n",
    "# calculates the probabilities for each token in model dictionaries\n",
    "def calculate_probs():\n",
    "    # positive prob\n",
    "    for first_token in model_p:\n",
    "        total_freq = float(sum(model_p[first_token].values()))\n",
    "        for second_token in model_p[first_token]:\n",
    "            # assign prob values to the model keys\n",
    "            prob_model_p[first_token][second_token] = model_p[first_token][second_token] / total_freq  \n",
    "    # negative prob\n",
    "    for first_token in model_n:\n",
    "        total_freq = float(sum(model_n[first_token].values()))\n",
    "        for second_token in model_n[first_token]:\n",
    "            # assign prob values to the model keys\n",
    "            prob_model_n[first_token][second_token] = model_n[first_token][second_token] / total_freq\n",
    "\n",
    "# makes the positive & negative models by the given csv\n",
    "def make_models(path):\n",
    "    #get line seperated samples\n",
    "    data = get_dataset(path)\n",
    "    \n",
    "    for sample in data:\n",
    "        #split the samples into comment & polarity\n",
    "        # delimiter - '::'\n",
    "        [comment, polarity] = sample.split('::')\n",
    "    \n",
    "        #1 = positive comments\n",
    "        if (polarity == '1'):\n",
    "            bigrams = make_bigrams(comment) # get the list of bigrams from comment\n",
    "            # count the token frequencies for each bigram\n",
    "            for bi in bigrams:\n",
    "                model_p[bi[0]][bi[1]] += 1\n",
    "                    \n",
    "        #0 = negative comments\n",
    "        if (polarity == '0'):\n",
    "            bigrams = make_bigrams(comment)\n",
    "            for bi in bigrams:\n",
    "                model_n[bi[0]][bi[1]] += 1\n",
    "                \n",
    "    # finally create the probability models\n",
    "    calculate_probs()\n",
    "    \n",
    "\n",
    "# calculates & displays the polarity of a given comment\n",
    "def check_sentiment(comment):\n",
    "    positive_score = 0.0\n",
    "    negative_score = 0.0\n",
    "    \n",
    "    bigrams = make_bigrams(comment)\n",
    "    for [first_token, second_token] in bigrams:\n",
    "        positive_score = prob_model_p[first_token][second_token]\n",
    "        negative_score = prob_model_n[first_token][second_token]\n",
    "    \n",
    "    print('Positive: ', positive_score)\n",
    "    print('Negative: ', negative_score, '\\n')\n",
    "    \n",
    "    if (positive_score > negative_score):\n",
    "        print('Sentiment: Positive')\n",
    "    elif (positive_score < negative_score):\n",
    "        print('Sentiment: Negative')\n",
    "    else:\n",
    "        print('Sentiment: Neutral')\n",
    "\n",
    "# calculates the perplexity of the model using the goven comment\n",
    "def perplexity():\n",
    "    \n",
    "    # calculate the vocabulary of the corpus\n",
    "    vocabulary_count = len(model_p) + len(model_n)\n",
    "    \n",
    "    for first in model_p:\n",
    "        vocabulary_count += len(model_p[first])\n",
    "    for first in model_n:\n",
    "        vocabulary_count += len(model_n[first])\n",
    "    \n",
    "    print('Vocabulary: ', vocabulary_count)\n",
    "    \n",
    "    bigram_prob = 1.\n",
    "    for first in prob_model_p:\n",
    "        prob_vals = prob_model_p[first].values()\n",
    "        for prob in prob_vals:\n",
    "            if prob != 0:\n",
    "                bigram_prob *= prob\n",
    "                \n",
    "    for first in prob_model_n:\n",
    "        prob_vals = prob_model_n[first].values()\n",
    "        for prob in prob_vals:\n",
    "            if prob != 0:\n",
    "                bigram_prob *= prob\n",
    "        \n",
    "    print('Bigram probability: ', bigram_prob, '\\n')\n",
    "    \n",
    "    # calculate the perplexity\n",
    "    pp = (1.0 / bigram_prob) ** (1. / vocabulary_count)\n",
    "    \n",
    "    print('perplexity: ', pp)\n",
    "\n",
    "# core functions end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ae34048ff8e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# execution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmake_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'comments.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# exection end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-b99356d6a5d4>\u001b[0m in \u001b[0;36mmake_models\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#split the samples into comment & polarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# delimiter - '::'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'::'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m#1 = positive comments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# execution\n",
    "\n",
    "make_models('political.txt')\n",
    "\n",
    "# exection end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  0.0\n",
      "Negative:  0.07142857142857142 \n",
      "\n",
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "comment = 'me rata'\n",
    "check_sentiment(comment)\n",
    "\n",
    "# test end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocalbulary:  1925 \n",
      "\n",
      "1.3508135619079657e-216\n",
      "perplexity:  1.2946129603986019\n"
     ]
    }
   ],
   "source": [
    "# perplexity\n",
    "\n",
    "perplexity()\n",
    "\n",
    "# perplexity end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
